{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW3_1739846.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34a521f8717f4aebbc0ab1879347aa83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cffffe0396184ca7b708697c4a58d90e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36bbd57b62dd4a279dcbc9f29af208b1",
              "IPY_MODEL_9eb81b271756463caa7908045d3d5611",
              "IPY_MODEL_945b03cad78e4553bd28bb0bae28c5fc"
            ]
          }
        },
        "cffffe0396184ca7b708697c4a58d90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36bbd57b62dd4a279dcbc9f29af208b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e40e318d9551462e8738a5727d3881d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_290a814230124e1f91cec2603410651a"
          }
        },
        "9eb81b271756463caa7908045d3d5611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3ac3c657ea746d69fbb46f2439020cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_159208e019a845cf9088e96163d43c0e"
          }
        },
        "945b03cad78e4553bd28bb0bae28c5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_448ff1c165b246b8b3fee5399f7a5418",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 289kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d88d1259cbe14837ae2fcfc518ec80be"
          }
        },
        "e40e318d9551462e8738a5727d3881d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "290a814230124e1f91cec2603410651a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3ac3c657ea746d69fbb46f2439020cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "159208e019a845cf9088e96163d43c0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "448ff1c165b246b8b3fee5399f7a5418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d88d1259cbe14837ae2fcfc518ec80be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64d2243c28234e3b96762dd42d7057b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4eb2a6afcb2e488ba563beb6d405baa6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9e9413576d94276a2e265d77914136c",
              "IPY_MODEL_712fb12f771c4df88567a64295335422",
              "IPY_MODEL_4c04cce600954e56a23146edf7a399a5"
            ]
          }
        },
        "4eb2a6afcb2e488ba563beb6d405baa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9e9413576d94276a2e265d77914136c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47fb248e4dc54486821ffb9d6e2da70e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06af2a87b37546efa260b4b80bda2ea2"
          }
        },
        "712fb12f771c4df88567a64295335422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2c0c47fe46440008e4cebdf6075e00b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3180df9537374f04a59c24604841433c"
          }
        },
        "4c04cce600954e56a23146edf7a399a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_564d1232cd2347debfaa9a699dcb880c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 612B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84adf90e40724d9f8e8c3128d9937595"
          }
        },
        "47fb248e4dc54486821ffb9d6e2da70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06af2a87b37546efa260b4b80bda2ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2c0c47fe46440008e4cebdf6075e00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3180df9537374f04a59c24604841433c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "564d1232cd2347debfaa9a699dcb880c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84adf90e40724d9f8e8c3128d9937595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a051563d7e9b419bb2383206f4a1fd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5d8bf18d1a964fc88bd589d3897bbce2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd25da578aea43e7bef6163ce2123dba",
              "IPY_MODEL_b3564d2e79d94b1c97911ba6c19e9bad",
              "IPY_MODEL_7ddd2e412d4b4deaa672f5997fcd3a03"
            ]
          }
        },
        "5d8bf18d1a964fc88bd589d3897bbce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd25da578aea43e7bef6163ce2123dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b46c6e54d76a436b8931110bb8888a89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cf3eaea8853488c851a29eb1a676e90"
          }
        },
        "b3564d2e79d94b1c97911ba6c19e9bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a49a4705d1d4ef7855d58ae86599ac0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02654022795446c3b854af646dd98961"
          }
        },
        "7ddd2e412d4b4deaa672f5997fcd3a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf1137d4af02430480b9990220707c5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 686kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0fb10c60e8d43279386414311506022"
          }
        },
        "b46c6e54d76a436b8931110bb8888a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cf3eaea8853488c851a29eb1a676e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a49a4705d1d4ef7855d58ae86599ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02654022795446c3b854af646dd98961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf1137d4af02430480b9990220707c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0fb10c60e8d43279386414311506022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b660002aaa47418c81179a50dfecf8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2932f4cf5da42ca9e84788c9e1942de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b889dfe62d414b7e8d9b07df71edc92e",
              "IPY_MODEL_a0f5861e792a45c98989378296a35067",
              "IPY_MODEL_f5a5396e293b4ffaaf67f69a7c77354b"
            ]
          }
        },
        "c2932f4cf5da42ca9e84788c9e1942de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b889dfe62d414b7e8d9b07df71edc92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f317b8eda3d547a7979c544013ca3bf0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09b327108a5e49218994f0b93f2ab835"
          }
        },
        "a0f5861e792a45c98989378296a35067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5bf8ed3147a14c5cb6d2858801c86f74",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a13442868dab496d9552c5cd4caaa877"
          }
        },
        "f5a5396e293b4ffaaf67f69a7c77354b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dbed4e3b5b1e470d86a64b47276781f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 13.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eb188281aa44f2586beedf27f708385"
          }
        },
        "f317b8eda3d547a7979c544013ca3bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09b327108a5e49218994f0b93f2ab835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bf8ed3147a14c5cb6d2858801c86f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a13442868dab496d9552c5cd4caaa877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbed4e3b5b1e470d86a64b47276781f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eb188281aa44f2586beedf27f708385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5976f40ddf20420eb0ad335cff58d1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12487def4f4543d8ba66e90105f028b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b08945d2895e4c5aa3e8d8182051d96f",
              "IPY_MODEL_ac8a44277fa24afb930cfe4560cfc6d4",
              "IPY_MODEL_6a3a67fe0d9c42f4ac0022edf5826af9"
            ]
          }
        },
        "12487def4f4543d8ba66e90105f028b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b08945d2895e4c5aa3e8d8182051d96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92b99f37d3434389842a5f3924011a93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_792e84f0578141b7bcc2cd152e9b9dc8"
          }
        },
        "ac8a44277fa24afb930cfe4560cfc6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae541bcae63f4007a992d24f2c9a9720",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27887bc5c5fe404892ab1c8d1bb66346"
          }
        },
        "6a3a67fe0d9c42f4ac0022edf5826af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_539c3c4abb684be1be1a3204b253c768",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e2311bc9f074ab29f060282185ef467"
          }
        },
        "92b99f37d3434389842a5f3924011a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "792e84f0578141b7bcc2cd152e9b9dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae541bcae63f4007a992d24f2c9a9720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27887bc5c5fe404892ab1c8d1bb66346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "539c3c4abb684be1be1a3204b253c768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e2311bc9f074ab29f060282185ef467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "127630dc89c849848af4d6be61763ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c9fb24bab324e70862420141429c2b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b03cc4f75d1b47ebb519edbb52e310c7",
              "IPY_MODEL_49c3a3afce074615aac1739caa9e1b0d",
              "IPY_MODEL_9dcaaa9fc2ec421d9a745957b686caa3"
            ]
          }
        },
        "9c9fb24bab324e70862420141429c2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b03cc4f75d1b47ebb519edbb52e310c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39c3c75d70aa4755b8e30b1830f5ebc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0:  10%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3747c931e684428c8b1c02a41c2a6b4d"
          }
        },
        "49c3a3afce074615aac1739caa9e1b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b6fb441b70a8490fbe1a271f604f28bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 52008,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52227324dfec4cc98326f8e2612ed6dd"
          }
        },
        "9dcaaa9fc2ec421d9a745957b686caa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eeb390d53ce64e03a4aa741402e693e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5400/52008 [36:48&lt;5:17:41,  2.45it/s, loss=0.828, v_num=0, train_loss=0.751]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddcf0bafa80346f8a3e9ab5c5d89cecd"
          }
        },
        "39c3c75d70aa4755b8e30b1830f5ebc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3747c931e684428c8b1c02a41c2a6b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6fb441b70a8490fbe1a271f604f28bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52227324dfec4cc98326f8e2612ed6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eeb390d53ce64e03a4aa741402e693e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddcf0bafa80346f8a3e9ab5c5d89cecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "204c3de7601a4f738531991c0f9b53de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_389d8a1e8a6f43fcbb5e4b85bf1198b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e68d82324a7d4ee58feb416f6df2fb1e",
              "IPY_MODEL_94ebdcd7d657436f9edb327c010dc6cb",
              "IPY_MODEL_3ee3b592a51a44048519258a123ff00b"
            ]
          }
        },
        "389d8a1e8a6f43fcbb5e4b85bf1198b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e68d82324a7d4ee58feb416f6df2fb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2627b223040424bac87bbacb993891f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33f936e7c3c44022b86e8e7e8a0b690e"
          }
        },
        "94ebdcd7d657436f9edb327c010dc6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_934bf32c327a4695a92acc3f1cd7b5f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9af7945b46b04beebf81a5a5c7bff00b"
          }
        },
        "3ee3b592a51a44048519258a123ff00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3adbc257c11411c8374a33130621cff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1727/1727 [03:41&lt;00:00,  8.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_122f9f3e99d441908575e0224324bba2"
          }
        },
        "a2627b223040424bac87bbacb993891f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33f936e7c3c44022b86e8e7e8a0b690e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "934bf32c327a4695a92acc3f1cd7b5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9af7945b46b04beebf81a5a5c7bff00b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3adbc257c11411c8374a33130621cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "122f9f3e99d441908575e0224324bba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "141218fe32b34360b32d4f7ac75493a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43b7187041ed4d7790824a9e6cf7d327",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b4a653926af415a9cb29c6f13f17a6a",
              "IPY_MODEL_fef247af95374ed59b1cc58c166521a3",
              "IPY_MODEL_ad46b865c65947718d373c98d3b0f183"
            ]
          }
        },
        "43b7187041ed4d7790824a9e6cf7d327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "2b4a653926af415a9cb29c6f13f17a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e98b82996764b1d97c70982e8aee4ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4785e8683a5d46a79463f6fbf82eb0e6"
          }
        },
        "fef247af95374ed59b1cc58c166521a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b4c5c5de2534d3eb31c1c4d106f9dc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f023c6b817cd4e82ae4f3976cfe0dd39"
          }
        },
        "ad46b865c65947718d373c98d3b0f183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cab2582298534bd1b73cccd7516dc36a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445/445 [00:40&lt;00:00, 10.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cc264f8b4ce4d8abef02f61f3968bdf"
          }
        },
        "9e98b82996764b1d97c70982e8aee4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4785e8683a5d46a79463f6fbf82eb0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b4c5c5de2534d3eb31c1c4d106f9dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f023c6b817cd4e82ae4f3976cfe0dd39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cab2582298534bd1b73cccd7516dc36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cc264f8b4ce4d8abef02f61f3968bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-njeIKywcnO"
      },
      "source": [
        "# **Homework 3 - WSD of WiC**\n",
        "## Michela Proietti 1739846"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEbbewuZwrqs"
      },
      "source": [
        "First of all, we install missing libraries, we make all the needed imports and define all the paths to data and the tokenizer that will be used in different parts of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ukqo8t1BYGB",
        "outputId": "c3737755-ebb4-4007-c332-c9436324d0cf"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install pytorch-lightning\n",
        "! pip install json-lines"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 27.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n",
            "\u001b[K     |████████████████████████████████| 916 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 21.3 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.0\n",
            "  Downloading torchmetrics-0.5.0-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (5.4.1)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 48.0 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.39.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.5.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=60a450bf3eb95e77fc29ba986cddf814e9e4ccec8a41964bfbde7a9a9d6e3f5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.7.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.1 pytorch-lightning-1.4.2 torchmetrics-0.5.0 yarl-1.6.3\n",
            "Collecting json-lines\n",
            "  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from json-lines) (1.15.0)\n",
            "Installing collected packages: json-lines\n",
            "Successfully installed json-lines-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTgvmDc4OSHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5399ce-0ad3-4940-9ce1-0619c9226580"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fr9fek1gfw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ff27df-1439-4472-ff6f-f3f4982fb00f"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, AdamW\n",
        "from torchmetrics.classification.accuracy import Accuracy\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import seaborn as sns\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from collections import defaultdict\n",
        "from typing import *\n",
        "import torch.nn as nn\n",
        "import torchmetrics\n",
        "import collections\n",
        "import torch\n",
        "import json_lines\n",
        "import tqdm\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7_U2ze2gpp2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "34a521f8717f4aebbc0ab1879347aa83",
            "cffffe0396184ca7b708697c4a58d90e",
            "36bbd57b62dd4a279dcbc9f29af208b1",
            "9eb81b271756463caa7908045d3d5611",
            "945b03cad78e4553bd28bb0bae28c5fc",
            "e40e318d9551462e8738a5727d3881d1",
            "290a814230124e1f91cec2603410651a",
            "e3ac3c657ea746d69fbb46f2439020cf",
            "159208e019a845cf9088e96163d43c0e",
            "448ff1c165b246b8b3fee5399f7a5418",
            "d88d1259cbe14837ae2fcfc518ec80be",
            "64d2243c28234e3b96762dd42d7057b8",
            "4eb2a6afcb2e488ba563beb6d405baa6",
            "c9e9413576d94276a2e265d77914136c",
            "712fb12f771c4df88567a64295335422",
            "4c04cce600954e56a23146edf7a399a5",
            "47fb248e4dc54486821ffb9d6e2da70e",
            "06af2a87b37546efa260b4b80bda2ea2",
            "c2c0c47fe46440008e4cebdf6075e00b",
            "3180df9537374f04a59c24604841433c",
            "564d1232cd2347debfaa9a699dcb880c",
            "84adf90e40724d9f8e8c3128d9937595",
            "a051563d7e9b419bb2383206f4a1fd07",
            "5d8bf18d1a964fc88bd589d3897bbce2",
            "dd25da578aea43e7bef6163ce2123dba",
            "b3564d2e79d94b1c97911ba6c19e9bad",
            "7ddd2e412d4b4deaa672f5997fcd3a03",
            "b46c6e54d76a436b8931110bb8888a89",
            "6cf3eaea8853488c851a29eb1a676e90",
            "6a49a4705d1d4ef7855d58ae86599ac0",
            "02654022795446c3b854af646dd98961",
            "bf1137d4af02430480b9990220707c5d",
            "f0fb10c60e8d43279386414311506022",
            "b660002aaa47418c81179a50dfecf8f0",
            "c2932f4cf5da42ca9e84788c9e1942de",
            "b889dfe62d414b7e8d9b07df71edc92e",
            "a0f5861e792a45c98989378296a35067",
            "f5a5396e293b4ffaaf67f69a7c77354b",
            "f317b8eda3d547a7979c544013ca3bf0",
            "09b327108a5e49218994f0b93f2ab835",
            "5bf8ed3147a14c5cb6d2858801c86f74",
            "a13442868dab496d9552c5cd4caaa877",
            "dbed4e3b5b1e470d86a64b47276781f5",
            "5eb188281aa44f2586beedf27f708385"
          ]
        },
        "outputId": "940b56ac-7e43-476e-91cd-2568f68c376a"
      },
      "source": [
        "train_data_path = \"/content/drive/MyDrive/NLP/Homework3/SemCor/semcor.data.xml\"\n",
        "val_data_path = \"/content/drive/MyDrive/NLP/Homework3/Data_Validation/sample-dataset/semeval2015.data.xml\"\n",
        "test_data_path = \"/content/drive/MyDrive/NLP/Homework3/Evaluation_Datasets/ALL/ALL.data.xml\"\n",
        "\n",
        "train_preprocessed = \"/content/drive/MyDrive/NLP/Homework3/SemCor/semcor_gloss_example.csv\"\n",
        "val_preprocessed = \"/content/drive/MyDrive/NLP/Homework3/Data_Validation/sample-dataset/semeval2015_gloss_example.csv\"\n",
        "test_preprocessed = \"/content/drive/MyDrive/NLP/Homework3/Evaluation_Datasets/ALL/ALL_gloss_example.csv\"\n",
        "\n",
        "bert_inputs_train = \"/content/drive/MyDrive/NLP/Homework3/train_dataset_gloss_example.csv\"\n",
        "bert_inputs_val = \"/content/drive/MyDrive/NLP/Homework3/val_dataset_gloss_example.csv\"\n",
        "bert_inputs_test = \"/content/drive/MyDrive/NLP/Homework3/test_dataset_gloss_example.csv\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34a521f8717f4aebbc0ab1879347aa83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d2243c28234e3b96762dd42d7057b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a051563d7e9b419bb2383206f4a1fd07",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b660002aaa47418c81179a50dfecf8f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXhxiQQoxSiz"
      },
      "source": [
        "The following function is used to retrieve the correct wordnet POS tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGtuBKDB89qB"
      },
      "source": [
        "def get_wordnet_postag(pos):\n",
        "    if pos == 'ADJ':\n",
        "        return wn.ADJ\n",
        "    elif pos.startswith('VERB'):\n",
        "        return wn.VERB\n",
        "    elif pos.startswith('NOUN'):\n",
        "        return wn.NOUN\n",
        "    elif pos.startswith('ADVERB'):\n",
        "        return wn.ADV\n",
        "    else:\n",
        "        return ''"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srReYwbbxaM7"
      },
      "source": [
        "## **Preprocessing of the WSD data**\n",
        "Here we preprocess the data that is needed to train and evaluate our WSD model. For each sentence that contains a word to be disambiguated, we retrieve all the relevant information, namely the lemma, the pos tag, the id of the instance to be disambiguated and the gold_key. Then, we find all senses that the considered word can have and for each of them we get the corresponding gloss. After all these steps, for each word to be disambiguated, so for each sentence, we will have as many samples as the number of senses that the word can have. So, we use a line that has as first element the number of samples we have for that instance, and all 'X' after that. These lines are used when we build the dataset in order to correctly structure the batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-yQYY6cg5IP"
      },
      "source": [
        "# Function used to get the gold keys from the corresponding file\n",
        "def get_gold_keys(path: str):\n",
        "    gold_keys = []\n",
        "    with open(path[:-len('.data.xml')] + '.gold.key.txt', \"r\", encoding=\"utf-8\") as f:\n",
        "          key = f.readline().strip().split()\n",
        "          while key:\n",
        "              gold_keys.append(key[1])\n",
        "              key = f.readline().strip().split()\n",
        "    return gold_keys\n",
        "\n",
        "# Function that get all the relevant information from the file contaning data\n",
        "def get_data(input_path: str):\n",
        "    data = ET.ElementTree(file=input_path)\n",
        "    root = data.getroot()\n",
        "\n",
        "    sentences = []\n",
        "    lemmas = []\n",
        "    poss = []\n",
        "    targets = []\n",
        "    targets_start_idxs = []\n",
        "    targets_end_idxs = []\n",
        "    sense_keys = []\n",
        "    instances = []\n",
        "\n",
        "    for text in root:\n",
        "        for s in text:\n",
        "            sentence = []\n",
        "            lemma = []\n",
        "            pos = []\n",
        "            target = []\n",
        "            target_start_idx = []\n",
        "            target_end_idx = []\n",
        "            instance = []\n",
        "\n",
        "            for token in s:\n",
        "                assert token.tag == 'wf' or token.tag == 'instance'\n",
        "                if token.tag == 'wf':\n",
        "                    for i in token.text.split(' '):\n",
        "                        sentence.append(i)\n",
        "                        pos.append(get_wordnet_postag(token.attrib['pos']))\n",
        "                        target.append('X')\n",
        "                        lemma.append(token.attrib['lemma'])\n",
        "                if token.tag == 'instance':\n",
        "                    target_start = len(sentence)\n",
        "                    for i in token.text.split(' '):\n",
        "                        sentence.append(i)\n",
        "                        pos.append(get_wordnet_postag(token.attrib['pos']))\n",
        "                        target.append(token.attrib['id'])\n",
        "                        lemma.append(token.attrib['lemma'])\n",
        "                        instance.append(token.text)\n",
        "                    target_end = len(sentence)\n",
        "                    target_start_idx.append(target_start)\n",
        "                    target_end_idx.append(target_end)\n",
        "\n",
        "            sentences.append(sentence)\n",
        "            lemmas.append(lemma)\n",
        "            poss.append(pos)\n",
        "            targets.append(target)\n",
        "            targets_start_idxs.append(target_start_idx)\n",
        "            targets_end_idxs.append(target_end_idx)\n",
        "            instances.append(instance)\n",
        "\n",
        "    return sentences, lemmas, poss, targets, targets_start_idxs, targets_end_idxs, instances\n",
        "\n",
        "# Function that creates a csv file with the preprocessed data\n",
        "def prepare_data(input_path: str, output_path: str):\n",
        "    sentences, lemmas, poss, targets, targets_start_idxs, targets_end_idxs, instances = get_data(input_path)\n",
        "    gold_keys = get_gold_keys(input_path)\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as g:\n",
        "        g.write('sentence\\ttarget_id\\ttarget_lemma\\ttarget_pos\\tsense_key\\tinstance\\tsynset\\texamples\\tlabel\\n')\n",
        "        num = 0\n",
        "        for i in range(len(sentences)):\n",
        "            for j in range(len(targets_start_idxs[i])):\n",
        "                sentence = ' '.join(sentences[i])\n",
        "                target_start = targets_start_idxs[i][j]\n",
        "                target_end = targets_end_idxs[i][j]\n",
        "                target_id = targets[i][target_start]\n",
        "                target_lemma = lemmas[i][target_start]\n",
        "                target_pos = poss[i][target_start]\n",
        "                instance = instances[i][j]\n",
        "                gold_key = gold_keys[num]\n",
        "                num += 1\n",
        "\n",
        "                # We add a target token right before and after the target word to be disambiguated\n",
        "                sentence = sentence.replace(instance, '[TGT] ' + instance + ' [TGT]')\n",
        "              \n",
        "                # We retrieve all the senses that the target word can have\n",
        "                senses = wn.lemmas(target_lemma, target_pos)\n",
        "                g.write('\\t'.join((str(len(senses)), 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X')))\n",
        "                g.write('\\n')\n",
        "\n",
        "                # For each sense, we find the corresponding gloss and examples and we compute a label that is 1 if the sense key we are\n",
        "                # considering is equal to the gold key and 0 otherwise. Then, we save all the information in the csv file.\n",
        "                for sense in senses:\n",
        "                  synset = sense.synset()\n",
        "                  gloss = synset.definition()\n",
        "                  examples = ' '.join(synset.examples())\n",
        "                  if examples != '':\n",
        "                    gloss = gloss + ' [SEP] ' + examples\n",
        "                  label = int(sense.key() == gold_key)\n",
        "\n",
        "                  g.write('\\t'.join((sentence, target_id, target_lemma, target_pos, str(sense.key()), instance, str(synset), gloss, str(label))))\n",
        "                  g.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYf9nIqy9LEd"
      },
      "source": [
        "# We preprocess the training, validation and test data getting three different CSV files\n",
        "prepare_data(train_data_path, train_preprocessed)\n",
        "prepare_data(val_data_path, val_preprocessed)\n",
        "prepare_data(test_data_path, test_preprocessed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-0-b3AD0Vf_"
      },
      "source": [
        "## **Precomputing BERT inputs for the WSD data**\n",
        "The training used to stop at 1% of the first epoch, because CUDA used to go out of memory. The most immediate way to solve this problem was to precompute the inputs to be given to BERT and store them, instead of computing them while creating the dataset.\n",
        "\n",
        "As previously said, for each word in context we will have as many samples as the number of senses that it can have. Therefore, we will have mini-batches made up by all the samples referring to the same ambiguous word. For these mini-batches, just the label referring to the actual meaning of the word is 1, while all the others are 0. Our model will have to predict the index in the array of labels which refers to the correct meaning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7-h9DhV-Hn1"
      },
      "source": [
        "# We load the preprocessed data we had previously stored in csv files\n",
        "train_data = pd.read_csv(train_preprocessed,sep=\"\\t\",header=0).values\n",
        "val_data = pd.read_csv(val_preprocessed,sep=\"\\t\",header=0).values\n",
        "test_data = pd.read_csv(test_preprocessed,sep=\"\\t\",header=0).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNu4gxSa8V_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5b939f-f9d1-4947-d033-8f180bdcb41a"
      },
      "source": [
        "# As we can see, for each target word to be disambiguated, we have as many samples as its possible senses.\n",
        "# For example, the first word to be disambiguated is 'long', and it has 9 possible sense, so we have 9\n",
        "# different samples that contain the same sentence, but different glosses/examples and labels.\n",
        "for i in range(10):\n",
        "  print(train_data[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['9' 'X' 'X' 'X' 'X' 'X' 'X' 'X' 'X']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%3:00:02::' 'long' \"Synset('long.a.01')\"\n",
            " 'primarily temporal sense; being or indicating a relatively great or greater than average duration or passage of time or a duration as specified [SEP] a long life a long boring speech a long time a long friendship a long game long ago an hour long'\n",
            " '1']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%3:00:01::' 'long' \"Synset('long.a.02')\"\n",
            " 'primarily spatial sense; of relatively great or greater than average spatial extension or extension as specified [SEP] a long road a long distance contained many long words ten miles long'\n",
            " '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%5:00:00:tall:00' 'long'\n",
            " \"Synset('long.s.03')\"\n",
            " 'of relatively great height [SEP] a race of long gaunt men\"- Sherwood Anderson looked out the long French windows'\n",
            " '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%3:00:00::' 'long'\n",
            " \"Synset('retentive.a.01')\"\n",
            " 'good at remembering [SEP] a retentive mind tenacious memory' '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%3:00:05::' 'long' \"Synset('long.a.05')\"\n",
            " 'holding securities or commodities in expectation of a rise in prices [SEP] is long on coffee a long position in gold'\n",
            " '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%3:00:04::' 'long' \"Synset('long.a.06')\"\n",
            " \"(of speech sounds or syllables) of relatively long duration [SEP] the English vowel sounds in `bate', `beat', `bite', `boat', `boot' are long\"\n",
            " '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%5:00:00:unsound:00' 'long'\n",
            " \"Synset('long.s.07')\" 'involving substantial risk [SEP] long odds' '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%5:00:00:provident:00' 'long'\n",
            " \"Synset('farseeing.s.02')\"\n",
            " 'planning prudently for the future [SEP] large goals that required farsighted policies took a long view of the geopolitical issues'\n",
            " '0']\n",
            "['How [TGT] long [TGT] has it been since you reviewed the objectives of your benefit and service program ?'\n",
            " 'd000.s000.t000' 'long' 'a' 'long%5:00:00:abundant:00' 'long'\n",
            " \"Synset('long.s.09')\"\n",
            " 'having or being more than normal or necessary:\"long on brains\" [SEP] in long supply'\n",
            " '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWG2fhzz3FyZ"
      },
      "source": [
        "# This function uses BERT tokenizer to get the inputs for the BERT model and stores them in a csv file.\n",
        "# We create minibatches of samples that contain the same word to be disambiguated\n",
        "# but different glosses/examples and labels.\n",
        "def save_bert_inputs(data: str, output_file: str, tokenizer: BertTokenizer, wic: bool = False):\n",
        "  bert_inputs = []\n",
        "  pairs = []\n",
        "  \n",
        "  for line in tqdm.tqdm(data):\n",
        "      if (line[1] == 'X'):\n",
        "          minibatch_len = int(line[0])\n",
        "          if (pairs):\n",
        "            bert_inputs.append(pairs)\n",
        "            pairs = []\n",
        "          continue\n",
        "      elif (minibatch_len > 0):\n",
        "          bert_input = tokenizer(line[0], line[7], return_token_type_ids = True, return_attention_mask = True)\n",
        "          label = int(line[8])\n",
        "\n",
        "          pairs.append([bert_input[\"input_ids\"], bert_input[\"attention_mask\"], bert_input[\"token_type_ids\"], label])\n",
        "  \n",
        "  with open(output_file, 'w', encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n",
        "    writer.writerows(bert_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG_-RU5e4IXc",
        "outputId": "ac398483-b010-4f39-e644-f57512a79ae1"
      },
      "source": [
        "save_bert_inputs(train_data, bert_inputs_train, tokenizer)\n",
        "save_bert_inputs(val_data, bert_inputs_val, tokenizer)\n",
        "save_bert_inputs(test_data, bert_inputs_test, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1716315/1716315 [33:45<00:00, 847.40it/s]\n",
            "100%|██████████| 6442/6442 [00:07<00:00, 905.77it/s]\n",
            "100%|██████████| 48542/48542 [00:59<00:00, 809.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGEKLVvFCDbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884f9e7c-a903-476c-ef08-82170f32c9ae"
      },
      "source": [
        "# Here we simply show how the file is structured:\n",
        "# each row contains all the samples belonging to the same mini-batch\n",
        "# As we can see from the output, the first sample in the first mini-batch is the one\n",
        "# referring to the actual meaning of the word, since it is the only one with label 1.\n",
        "\n",
        "i = 0\n",
        "with open(bert_inputs_val) as f:\n",
        "    next(f)\n",
        "    csv_reader = csv.reader(f, delimiter=',')\n",
        "    for row in csv_reader:\n",
        "      for sample in row:\n",
        "        bert_inputs = sample.split('], ')\n",
        "\n",
        "        input_ids = bert_inputs[0][2::].split(',')\n",
        "        attention_mask = bert_inputs[1][1::].split(',')\n",
        "        token_type_ids = bert_inputs[2][1::].split(',')\n",
        "        label = int(bert_inputs[3][:1])\n",
        "\n",
        "        input_ids = torch.tensor(list(map(int, input_ids)))\n",
        "        attention_mask = torch.tensor(list(map(int, attention_mask)))\n",
        "        token_type_ids = torch.tensor(list(map(int, token_type_ids)))\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "        print(token_type_ids)\n",
        "        print(label)\n",
        "      print('######################################################')\n",
        "      i += 1\n",
        "      if (i == 2):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  2023, 30522,  6254, 30522,  2003,  1037, 12654,  1997,  1996,\n",
            "         2647,  2270,  7667,  3189,  1006, 19044,  2099,  1007,  1012,   102,\n",
            "         3015,  2008,  3640,  2592,  1006,  2926,  2592,  1997,  2019,  2880,\n",
            "         3267,  1007,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(1)\n",
            "tensor([  101,  2023, 30522,  6254, 30522,  2003,  1037, 12654,  1997,  1996,\n",
            "         2647,  2270,  7667,  3189,  1006, 19044,  2099,  1007,  1012,   102,\n",
            "         2505,  3529,  2004,  1037,  6630,  1997,  1037,  2711,  1005,  1055,\n",
            "         3241,  2011,  2965,  1997, 12613,  6017,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2023, 30522,  6254, 30522,  2003,  1037, 12654,  1997,  1996,\n",
            "         2647,  2270,  7667,  3189,  1006, 19044,  2099,  1007,  1012,   102,\n",
            "         1037,  2517,  4070,  1997,  6095,  2030, 14987,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2023, 30522,  6254, 30522,  2003,  1037, 12654,  1997,  1996,\n",
            "         2647,  2270,  7667,  3189,  1006, 19044,  2099,  1007,  1012,   102,\n",
            "         1006,  3274,  2671,  1007,  1037,  3274,  5371,  2008,  3397,  3793,\n",
            "         1006,  1998,  4298,  4289,  3436,  8128,  1007,  2478,  2698,  1011,\n",
            "         2978,  2004,  6895,  2072,  3494,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "######################################################\n",
            "tensor([  101,  2023,  6254,  2003,  1037, 30522, 12654, 30522,  1997,  1996,\n",
            "         2647,  2270,  7667,  3189,  1006, 19044,  2099,  1007,  1012,   102,\n",
            "         1037,  4766,  4861,  2008,  7534,  1996,  2364,  2685,  1999,  1037,\n",
            "         9530, 18380,  2433,   102,  2002,  2435,  1037, 12654,  1997,  1996,\n",
            "        15306,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(1)\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnGdiZD02FQQ"
      },
      "source": [
        "# **Dataset definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAvLb6gNOe00"
      },
      "source": [
        "# We zero-pad the sequences in the same sub_batch so that they have the same length\n",
        "def collate_function(batch):\n",
        "\n",
        "    collated_batch = []\n",
        "    for sub_batch in batch:\n",
        "        sub_collated = []\n",
        "        input_ids = [sample[0] for sample in sub_batch]\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
        "\n",
        "        attention_mask = [sample[1] for sample in sub_batch]\n",
        "        attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "\n",
        "        token_type_ids = [sample[2] for sample in sub_batch]\n",
        "        token_type_ids = torch.nn.utils.rnn.pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
        "\n",
        "        labels = [sample[3] for sample in sub_batch]\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "        collated_batch.append((input_ids, attention_mask, token_type_ids, labels))\n",
        "\n",
        "    return collated_batch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pibmTcRAOe03"
      },
      "source": [
        "class WSD_WiC_Dataset(Dataset):\n",
        "  \n",
        "  def __init__(self, data_path : str):\n",
        "    self.data = []\n",
        "    self.create_samples(data_path)\n",
        "\n",
        "  # We retrieve BERT inputs from the previously created csv files and we organize\n",
        "  # them in batches of elements, where each element is a mini-batch of samples as\n",
        "  # described above.\n",
        "  def create_samples(self, data_path):\n",
        "    with open(data_path) as f:\n",
        "      next(f)\n",
        "      csv_reader = csv.reader(f, delimiter=',')\n",
        "      for row in csv_reader:\n",
        "        samples = []\n",
        "        for sample in row:\n",
        "          bert_inputs = sample.split('], ')\n",
        "\n",
        "          input_ids = bert_inputs[0][2::].split(',')\n",
        "          attention_mask = bert_inputs[1][1::].split(',')\n",
        "          token_type_ids = bert_inputs[2][1::].split(',')\n",
        "          label = int(bert_inputs[3][:1])\n",
        "\n",
        "          input_ids = torch.tensor(list(map(int, input_ids)))\n",
        "          attention_mask = torch.tensor(list(map(int, attention_mask)))\n",
        "          token_type_ids = torch.tensor(list(map(int, token_type_ids)))\n",
        "          label = torch.tensor(label, dtype=torch.long)\n",
        "          \n",
        "          samples.append((input_ids, attention_mask, token_type_ids, label))\n",
        "    \n",
        "        self.data.append(samples)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8IAH-f-Oe04"
      },
      "source": [
        "class WSDDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_train: str, data_val: str,\n",
        "                data_test: str, batch_size: int, collate_fn=None) -> None:\n",
        "      super().__init__()\n",
        "      self.data_train = data_train\n",
        "      self.data_val = data_val\n",
        "      self.data_test = data_test\n",
        "      self.batch_size = batch_size\n",
        "      self.collate_fn = collate_fn\n",
        "      self.train_dataset = None\n",
        "      self.validation_dataset = None\n",
        "      self.test_dataset = None\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "      if stage == 'fit':\n",
        "        self.train_dataset = WSD_WiC_Dataset(self.data_train)\n",
        "        self.validation_dataset = WSD_WiC_Dataset(self.data_val)\n",
        "      elif stage == 'test':\n",
        "        self.test_dataset = WSD_WiC_Dataset(self.data_test)\n",
        "        \n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "      return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "      return DataLoader(self.validation_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "    def test_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "      return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNE-JRgyOe04"
      },
      "source": [
        "WSD_dm = WSDDataModule(data_train=bert_inputs_train,\n",
        "                      data_val=bert_inputs_val,\n",
        "                      data_test=bert_inputs_test,\n",
        "                      batch_size=4,\n",
        "                      collate_fn=collate_function)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LzsM5xbOe04",
        "outputId": "f2c23ae6-1fdc-44a5-c881-80f35ea90239"
      },
      "source": [
        "# We show how the batches are organized:\n",
        "# each batch is made up by sub_batches of variable length, and the length depends\n",
        "# on how many senses the target word we are considering has. In this case, the sub_batch\n",
        "# has 4 elements, which means there are 4 different sense keys that refer to the same\n",
        "# word, among which the first one corresponds to the gold key, since the tensor containing\n",
        "# the labels has 1 as first element.\n",
        "WSD_dm.setup('test')\n",
        "test_dataloader = WSD_dm.test_dataloader()\n",
        "for batch in test_dataloader:\n",
        "  print(f\"Batch length = : {len(batch)}\")\n",
        "  for sub_batch in batch:\n",
        "    print(f\"Sub-batch length = : {len(sub_batch)}\")\n",
        "    print(sub_batch)\n",
        "    break\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch length = : 4\n",
            "Sub-batch length = : 4\n",
            "(tensor([[  101,  1996, 30522,  2396, 30522,  1997,  2689,  1011, 13060,  2003,\n",
            "         14099,  2000,  1996,  2394,  1010,  1998,  1010,  2066,  2087,  2394,\n",
            "         14099,  6447,  1010,  4895, 18447, 13348, 18507,  2000,  1996,  2717,\n",
            "          1997,  1996,  2088,  1012,   102,  1996,  3688,  1997,  2529, 14842,\n",
            "          1025,  2573,  1997,  2396, 13643,   102,  2019,  2396,  4538,  1037,\n",
            "          2986,  3074,  1997,  2396,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  1996, 30522,  2396, 30522,  1997,  2689,  1011, 13060,  2003,\n",
            "         14099,  2000,  1996,  2394,  1010,  1998,  1010,  2066,  2087,  2394,\n",
            "         14099,  6447,  1010,  4895, 18447, 13348, 18507,  2000,  1996,  2717,\n",
            "          1997,  1996,  2088,  1012,   102,  1996,  4325,  1997,  3376,  2030,\n",
            "          3278,  2477,   102,  2396,  2515,  2025,  2342,  2000,  2022,  9525,\n",
            "          2000,  2022,  2204,  1045,  2001,  2196,  2151,  2204,  2012,  2396,\n",
            "          2002,  2056,  2008,  4294,  2003,  1996,  2396,  1997, 18313,  2686,\n",
            "         17950,   102],\n",
            "        [  101,  1996, 30522,  2396, 30522,  1997,  2689,  1011, 13060,  2003,\n",
            "         14099,  2000,  1996,  2394,  1010,  1998,  1010,  2066,  2087,  2394,\n",
            "         14099,  6447,  1010,  4895, 18447, 13348, 18507,  2000,  1996,  2717,\n",
            "          1997,  1996,  2088,  1012,   102,  1037,  6020,  8066,  2008,  2017,\n",
            "          2064,  4553,  2011,  2817,  1998,  3218,  1998,  8089,   102,  1996,\n",
            "          2396,  1997,  4512,  2009,  1005,  1055,  3243,  2019,  2396,   102,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  1996, 30522,  2396, 30522,  1997,  2689,  1011, 13060,  2003,\n",
            "         14099,  2000,  1996,  2394,  1010,  1998,  1010,  2066,  2087,  2394,\n",
            "         14099,  6447,  1010,  4895, 18447, 13348, 18507,  2000,  1996,  2717,\n",
            "          1997,  1996,  2088,  1012,   102,  7008,  2030,  2060,  5107, 15066,\n",
            "          1999,  1037,  6267,  4772,   102,  1996,  6674,  2001,  3625,  2005,\n",
            "          2035,  1996,  8266,  1999,  1996,  2338,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([0, 0, 1, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfBzKORaOe05"
      },
      "source": [
        "## **Model definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJAi82B4Oe05"
      },
      "source": [
        "class MyBERTModel(BertPreTrainedModel):\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "\n",
        "    # BERT pretrained embeddings\n",
        "    self.bert = BertModel(config)\n",
        "\n",
        "    # Dropout and linear layer to perform the classification\n",
        "    self.bert_dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    self.lin1 = torch.nn.Linear(config.hidden_size, 256)\n",
        "    self.lin2 = torch.nn.Linear(256, 128)\n",
        "    self.lin3 = torch.nn.Linear(128, 1)\n",
        "\n",
        "    self.dropout = torch.nn.Dropout(0.4)\n",
        "\n",
        "    self.init_weights()\n",
        "  \n",
        "  def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, token_type_ids:torch.Tensor):\n",
        "    out = self.bert(input_ids, attention_mask, token_type_ids)\n",
        "    out = self.bert_dropout(out[1])\n",
        "    out = self.lin1(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.lin2(out)\n",
        "    out = self.dropout(out)\n",
        "    logits = self.lin3(out).squeeze(-1)\n",
        "\n",
        "    return logits\n",
        "\n",
        "class WSDClassifier(pl.LightningModule):\n",
        "    def __init__(self, config, tokenizer):\n",
        "      super().__init__()\n",
        "\n",
        "      self.bert = MyBERTModel.from_pretrained('bert-base-uncased', config=config)\n",
        "      self.bert.resize_token_embeddings(len(tokenizer)) # Needed to account for the additional target token\n",
        "\n",
        "      # Defining loss function and metrics\n",
        "      self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "      self.val_acc = Accuracy()\n",
        "      self.test_acc = Accuracy()\n",
        "\n",
        "      self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, token_type_ids:torch.Tensor, y: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "      logits = self.bert(input_ids, attention_mask, token_type_ids)\n",
        "      result = {'logits': logits}\n",
        "\n",
        "      # We compute the loss and the index in the array of labels corresponding to \n",
        "      # the sense key that is equal to the gold key\n",
        "      if y is not None:\n",
        "        labels = torch.max(y, -1).indices.detach()\n",
        "        result['labels'] = labels.item()\n",
        "\n",
        "        loss = self.loss_fn(logits.unsqueeze(dim=0), labels.unsqueeze(dim=-1))\n",
        "        result['loss'] = loss\n",
        "        \n",
        "      return result\n",
        "\n",
        "    def training_step(self, batch: Tuple[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
        "      batch_loss = 0\n",
        "      for minibatch in batch:\n",
        "          output = self.forward(minibatch[0], minibatch[1], minibatch[2], minibatch[3])\n",
        "          batch_loss += output['loss']\n",
        "\n",
        "      self.log('train_loss', batch_loss/len(batch), prog_bar=True)\n",
        "      return batch_loss / len(batch)\n",
        "\n",
        "    def validation_step(self, batch: Tuple[torch.Tensor], batch_idx: int):\n",
        "      batch_loss = 0\n",
        "      predictions = []\n",
        "      labels = []\n",
        "\n",
        "      for minibatch in batch:\n",
        "          output = self.forward(minibatch[0], minibatch[1], minibatch[2], minibatch[3])\n",
        "          predictions.append(torch.argmax(output['logits'], dim=-1).item())\n",
        "          labels.append(output['labels'])\n",
        "          batch_loss += output['loss']\n",
        "\n",
        "      loss = batch_loss / len(batch)\n",
        "      self.log('val_loss', loss, prog_bar=True)\n",
        "      \n",
        "      return {\"loss\": loss, \"predictions\": predictions, \"labels\": labels}\n",
        "\n",
        "    # Function needed since each batch is organized in sub-batches\n",
        "    def validation_epoch_end(self, val_step_outputs):\n",
        "      predictions = []\n",
        "      labels = []\n",
        "      for val_step_output in val_step_outputs:\n",
        "        predictions.extend(val_step_output['predictions'])\n",
        "        labels.extend(val_step_output['labels'])\n",
        "\n",
        "      self.val_acc(torch.tensor(predictions), torch.tensor(labels))\n",
        "      self.log('val_acc', self.val_acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch: Tuple[torch.Tensor], batch_idx: int):\n",
        "      batch_loss = 0\n",
        "      predictions = []\n",
        "      labels = []\n",
        "      for minibatch in batch:\n",
        "          output = self.forward(minibatch[0], minibatch[1], minibatch[2], minibatch[3])\n",
        "          predictions.append(torch.argmax(output['logits'], dim=-1).item())\n",
        "          labels.append(output['labels'])\n",
        "          batch_loss += output['loss']\n",
        "\n",
        "      loss = batch_loss / len(batch)\n",
        "      self.log('test_loss', loss, prog_bar=True)\n",
        "      \n",
        "      return {\"loss\": loss, \"predictions\": predictions, \"labels\": labels}\n",
        "\n",
        "    # Function needed since each batch is organized in sub-batches\n",
        "    def test_epoch_end(self, test_step_outputs):\n",
        "      predictions = []\n",
        "      labels = []\n",
        "      for test_step_output in test_step_outputs:\n",
        "        predictions.extend(test_step_output['predictions'])\n",
        "        labels.extend(test_step_output['labels'])\n",
        "\n",
        "      self.test_acc(torch.tensor(predictions), torch.tensor(labels))\n",
        "      self.log('test_acc', self.test_acc, prog_bar=True)\n",
        "\n",
        "    # Function that outputs the predictions for the WSD task\n",
        "    def get_predictions(self, sentence: str, instance:str, pos: str, lemma: str, verbose=False):\n",
        "      # We add the target token to the sentence\n",
        "      sentence = sentence.replace(instance, '[TGT] ' + instance + ' [TGT]')\n",
        "\n",
        "      # We retrieve all possible senses for the target word\n",
        "      if (lemma is None):\n",
        "        senses = wn.lemmas(instance, pos)\n",
        "      else:\n",
        "        senses = wn.lemmas(lemma, pos)\n",
        "\n",
        "      keys = []\n",
        "      glosses = []\n",
        "\n",
        "      # For each sense we retrieve the corresponding sense key and gloss/examples\n",
        "      for sense in senses:\n",
        "        synset = sense.synset()\n",
        "        gloss = synset.definition()\n",
        "        examples = ' '.join(synset.examples())\n",
        "        if examples != '':\n",
        "          gloss = gloss + ' [SEP] ' + examples\n",
        "        keys.append(sense.key())\n",
        "        glosses.append(gloss)\n",
        "\n",
        "      # For each gloss, we get the BERT inputs, and append them to the samples array\n",
        "      samples = []\n",
        "      for gloss in glosses:\n",
        "\n",
        "        bert_inputs = tokenizer(sentence, gloss, return_token_type_ids = True, return_attention_mask = True)\n",
        "\n",
        "        samples.append((torch.tensor(bert_inputs[\"input_ids\"]), torch.tensor(bert_inputs[\"attention_mask\"]), torch.tensor(bert_inputs[\"token_type_ids\"]), None))\n",
        "\n",
        "      # We need torch.no_grad, because we don't want to change the weights of our model\n",
        "      # but just to get the output it gives\n",
        "      with torch.no_grad():\n",
        "        # initialize the logits\n",
        "        logits = torch.zeros(len(glosses), dtype=torch.double).to(device)\n",
        "        \n",
        "        # For each sample, we get the logits given as output by the model\n",
        "        for i, sample in list(enumerate(samples)):\n",
        "          input_ids = sample[0].unsqueeze(0).to(device)\n",
        "          attention_mask = sample[1].unsqueeze(0).to(device)\n",
        "          token_type_ids = sample[2].unsqueeze(0).to(device)\n",
        "\n",
        "          logits[i] = self.forward(input_ids, attention_mask, token_type_ids, None)['logits']\n",
        "\n",
        "        # We get the scores by applying the softmax function on the logits\n",
        "        scores = torch.softmax(logits, dim=0)\n",
        "\n",
        "      # We sort the predictions so that the first one is the most probable one\n",
        "      predictions = sorted(zip(keys, glosses, scores), key=lambda x: x[-1], reverse=True)\n",
        "\n",
        "      # We get the most probable sense key\n",
        "      try:\n",
        "        wsd_prediction = predictions[0][0]\n",
        "      except:\n",
        "        if lemma is not None:\n",
        "          return self.get_predictions(sentence.replace(instance, lemma), lemma, pos, None, False)\n",
        "        else:\n",
        "          return 'None'\n",
        "\n",
        "      # We plot the various senses and the corresponding scores\n",
        "      if verbose:\n",
        "        if predictions is not None:\n",
        "          print(\"OUTPUT PREDICTIONS:\\n\")\n",
        "          for i, (key, gloss, score) in enumerate(predictions):\n",
        "            print(f\"Sense key: {key}, Gloss + Examples: {gloss}\\n            => Score = {score}\\n\")\n",
        "      \n",
        "      return wsd_prediction\n",
        "\n",
        "    def predict(self, input_pairs):\n",
        "      wsd_predictions = []\n",
        "\n",
        "      for pair in input_pairs:\n",
        "        sentence1 = pair['sentence1']\n",
        "        sentence2 = pair['sentence2']\n",
        "\n",
        "        instance1 = sentence1[int(pair['start1']):int(pair['end1'])]\n",
        "        instance2 = sentence2[int(pair['start2']):int(pair['end2'])]\n",
        "\n",
        "        lemma = pair['lemma']\n",
        "        pos = pair['pos']\n",
        "\n",
        "        # We get the most probable sense for each of the two words in the two different contexts\n",
        "        wsd_sentence1 = self.get_predictions(sentence1.lower(), instance1.lower(), get_wordnet_postag(pos), lemma, False)\n",
        "        wsd_sentence2 = self.get_predictions(sentence2.lower(), instance2.lower(), get_wordnet_postag(pos), lemma, False)\n",
        "        \n",
        "        wsd_predictions.append((wsd_sentence1, wsd_sentence2))\n",
        "      \n",
        "      # We check whether the two wsd predictions are the same, meaning that the two words are used with the\n",
        "      # same meaning in the two different contexts.\n",
        "      wic_predictions = ['True' if prediction[0]==prediction[1] else 'False' for prediction in wsd_predictions]\n",
        "              \n",
        "      return wic_predictions, wsd_predictions\n",
        "\n",
        "    def loss(self, pred, y):\n",
        "      return self.loss_fn(pred, y)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      params = list(self.bert.named_parameters())\n",
        "      no_decay = [\"bias\", \"gamma\", \"beta\"]\n",
        "      optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in params if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay_rate\": 0.01\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in params if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay_rate\": 0.0\n",
        "            }]\n",
        "\n",
        "      optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)\n",
        "      return optimizer"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX9EP65EOe06",
        "outputId": "e000a9b8-062f-4d14-f8a6-8d69c861db5a"
      },
      "source": [
        "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=2, hidden_dropout_prob=0.1, hidden_size=768)\n",
        "model = WSDClassifier(config, tokenizer).to(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing MyBERTModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing MyBERTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MyBERTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of MyBERTModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['lin3.weight', 'lin1.bias', 'lin3.bias', 'lin1.weight', 'lin2.bias', 'lin2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_D395fROe06"
      },
      "source": [
        "def get_trainer() -> pl.Trainer:\n",
        "    # If the validation accuracy does not increase for 3 epochs we perform early stopping and the training ends\n",
        "    early_stopping = pl.callbacks.EarlyStopping(\n",
        "    monitor='val_acc',\n",
        "    patience=2,\n",
        "    verbose=True,\n",
        "    mode='max')\n",
        "\n",
        "    # We define the trainer, setting the maximum number of epochs to 10\n",
        "    trainer = pl.Trainer(max_epochs=4, gpus=1, progress_bar_refresh_rate=50, callbacks=[early_stopping]) # BERT paper suggets max_epochs = 2, 3, 4\n",
        "    \n",
        "    return trainer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiQMIvqTOnWv"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBlzLnvOe06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786,
          "referenced_widgets": [
            "5976f40ddf20420eb0ad335cff58d1b2",
            "12487def4f4543d8ba66e90105f028b0",
            "b08945d2895e4c5aa3e8d8182051d96f",
            "ac8a44277fa24afb930cfe4560cfc6d4",
            "6a3a67fe0d9c42f4ac0022edf5826af9",
            "92b99f37d3434389842a5f3924011a93",
            "792e84f0578141b7bcc2cd152e9b9dc8",
            "ae541bcae63f4007a992d24f2c9a9720",
            "27887bc5c5fe404892ab1c8d1bb66346",
            "539c3c4abb684be1be1a3204b253c768",
            "3e2311bc9f074ab29f060282185ef467",
            "127630dc89c849848af4d6be61763ddc",
            "9c9fb24bab324e70862420141429c2b7",
            "b03cc4f75d1b47ebb519edbb52e310c7",
            "49c3a3afce074615aac1739caa9e1b0d",
            "9dcaaa9fc2ec421d9a745957b686caa3",
            "39c3c75d70aa4755b8e30b1830f5ebc2",
            "3747c931e684428c8b1c02a41c2a6b4d",
            "b6fb441b70a8490fbe1a271f604f28bd",
            "52227324dfec4cc98326f8e2612ed6dd",
            "eeb390d53ce64e03a4aa741402e693e6",
            "ddcf0bafa80346f8a3e9ab5c5d89cecd"
          ]
        },
        "outputId": "92dd3023-96fd-4149-cdf1-405dea047d98"
      },
      "source": [
        "# We define the trainer and train our model\n",
        "trainer = get_trainer()\n",
        "trainer.fit(model=model, datamodule=WSD_dm)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type             | Params\n",
            "----------------------------------------------\n",
            "0 | bert     | MyBERTModel      | 109 M \n",
            "1 | loss_fn  | CrossEntropyLoss | 0     \n",
            "2 | val_acc  | Accuracy         | 0     \n",
            "3 | test_acc | Accuracy         | 0     \n",
            "----------------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "438.852   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5976f40ddf20420eb0ad335cff58d1b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "127630dc89c849848af4d6be61763ddc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: -1it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8443b8a8114a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We define the trainer and train our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWSD_dm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# reset trainer on this loop and all child loops in case user connected a custom loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mrank_zero_warn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Detected KeyboardInterrupt, attempting graceful shutdown...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mepoch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, dataloader_iter, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_seen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_started\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttributeDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# free memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, batch_idx, split_batch, opt_idx, optimizer)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_TPU_AVAILABLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         )\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \"\"\"\n\u001b[0;32m-> 1618\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         )\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mrun_optimizer_step\u001b[0;34m(self, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     ) -> None:\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36m_training_step_and_backward_closure\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens, return_result)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step_and_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip_backward\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-2a0d288826ac>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m           \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-2a0d288826ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-2a0d288826ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.76 GiB total capacity; 13.29 GiB already allocated; 25.75 MiB free; 13.67 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMtmL-MSAkZZ"
      },
      "source": [
        "# We save the model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/Homework3/Results/trained_model_gloss_examples_256-128-d4.pth\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbDfHKjz9k9Y"
      },
      "source": [
        "### **Evaluation on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "204c3de7601a4f738531991c0f9b53de",
            "389d8a1e8a6f43fcbb5e4b85bf1198b0",
            "e68d82324a7d4ee58feb416f6df2fb1e",
            "94ebdcd7d657436f9edb327c010dc6cb",
            "3ee3b592a51a44048519258a123ff00b",
            "a2627b223040424bac87bbacb993891f",
            "33f936e7c3c44022b86e8e7e8a0b690e",
            "934bf32c327a4695a92acc3f1cd7b5f0",
            "9af7945b46b04beebf81a5a5c7bff00b",
            "d3adbc257c11411c8374a33130621cff",
            "122f9f3e99d441908575e0224324bba2"
          ]
        },
        "id": "j4-cSwFLtmXZ",
        "outputId": "378c3b7e-2914-4fcd-faaf-f850e283c860"
      },
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/Homework3/Results/trained_model_gloss_examples_256-128-d4.pth\"))\n",
        "model.eval()\n",
        "\n",
        "trainer = get_trainer()\n",
        "trainer.test(model=model, datamodule=WSD_dm)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "204c3de7601a4f738531991c0f9b53de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.7131479978561401, 'test_loss': 0.9504134058952332}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_acc': 0.7131479978561401, 'test_loss': 0.9504134058952332}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uen2e6F1ApT",
        "outputId": "f11ddd4b-0dd3-4880-b394-75ab8c28872e"
      },
      "source": [
        "sentence =  'How long has it been since you reviewed the objectives of your benefit and service program ?'\n",
        "\n",
        "prediction = model.get_predictions(sentence, 'long', get_wordnet_postag('ADJ'), None, verbose=True)\n",
        "print(f\"The most probable sense key is: {prediction}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUT PREDICTIONS:\n",
            "\n",
            "Sense key: long%3:00:02::, Gloss + Examples: primarily temporal sense; being or indicating a relatively great or greater than average duration or passage of time or a duration as specified [SEP] a long life a long boring speech a long time a long friendship a long game long ago an hour long\n",
            "            => Score = 0.9634765684486432\n",
            "\n",
            "Sense key: long%5:00:00:provident:00, Gloss + Examples: planning prudently for the future [SEP] large goals that required farsighted policies took a long view of the geopolitical issues\n",
            "            => Score = 0.028436554624019013\n",
            "\n",
            "Sense key: long%3:00:01::, Gloss + Examples: primarily spatial sense; of relatively great or greater than average spatial extension or extension as specified [SEP] a long road a long distance contained many long words ten miles long\n",
            "            => Score = 0.005806163313303585\n",
            "\n",
            "Sense key: long%5:00:00:abundant:00, Gloss + Examples: having or being more than normal or necessary:\"long on brains\" [SEP] in long supply\n",
            "            => Score = 0.0005718203119122254\n",
            "\n",
            "Sense key: long%3:00:00::, Gloss + Examples: good at remembering [SEP] a retentive mind tenacious memory\n",
            "            => Score = 0.00046192432227790635\n",
            "\n",
            "Sense key: long%3:00:05::, Gloss + Examples: holding securities or commodities in expectation of a rise in prices [SEP] is long on coffee a long position in gold\n",
            "            => Score = 0.00035878647957294076\n",
            "\n",
            "Sense key: long%5:00:00:unsound:00, Gloss + Examples: involving substantial risk [SEP] long odds\n",
            "            => Score = 0.0003349227197956842\n",
            "\n",
            "Sense key: long%5:00:00:tall:00, Gloss + Examples: of relatively great height [SEP] a race of long gaunt men\"- Sherwood Anderson looked out the long French windows\n",
            "            => Score = 0.0002972791079749561\n",
            "\n",
            "Sense key: long%3:00:04::, Gloss + Examples: (of speech sounds or syllables) of relatively long duration [SEP] the English vowel sounds in `bate', `beat', `bite', `boat', `boot' are long\n",
            "            => Score = 0.0002559806725006078\n",
            "\n",
            "The most probable sense key is: long%3:00:02::\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NAlUnBSWVoL"
      },
      "source": [
        "## **Preprocessing of WiC data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MXRmECRVrvN"
      },
      "source": [
        "path_to_val_data = '/content/drive/MyDrive/NLP/Homework3/WiC/dev.jsonl'\n",
        "path_to_val_keys = '/content/drive/MyDrive/NLP/Homework3/WiC/dev_wsd.txt'\n",
        "bert_inputs_wic = '/content/drive/MyDrive/NLP/Homework3/WiC/bert_inputs_gloss_examples.csv'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIDMC9TpQDAO"
      },
      "source": [
        "# We get the gold keys that represent the labels for the WSD task\n",
        "def get_wsd_labels(path: str):\n",
        "  labels = []\n",
        "  with open(path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      id, gold_key = line.split()\n",
        "      labels.append(gold_key)\n",
        "  return labels\n",
        "\n",
        "# We get the labels for the WiC task\n",
        "def get_wic_labels(path:str):\n",
        "  labels = []\n",
        "  with open(path) as f:\n",
        "    for line in json_lines.reader(f):\n",
        "      labels.append(line['label'])\n",
        "  return labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxT2b1BWWYFT"
      },
      "source": [
        "# Returns the gold keys for the WiC data\n",
        "def get_wic_keys(path: str):\n",
        "  gold_keys = dict()\n",
        "  with open(path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      id, gold_key = line.split()\n",
        "      gold_keys[id] = gold_key\n",
        "  return gold_keys\n",
        "\n",
        "# We preprocess both sentences in the WiC dataset, we get the glosses for each possible sense\n",
        "# of the word to disambiguate and we tokenize the concatenation of the sentence and the glosses\n",
        "# to precompute the inputs for the BERT model and store them in a csv file\n",
        "def preprocess_wic_data(data_path:str, keys_path:str, output_file: str, tokenizer: BertTokenizer):\n",
        "  sentences = []\n",
        "  poss = []\n",
        "  lemmas = []\n",
        "  ids = []\n",
        "  instances = []\n",
        "  keys = []\n",
        "  bert_inputs = []\n",
        "\n",
        "  gold_keys = get_wic_keys(keys_path)\n",
        "\n",
        "  with open(data_path) as f:\n",
        "    for line in json_lines.reader(f):\n",
        "      sentence1 = line['sentence1']\n",
        "      sentence2 = line['sentence2']\n",
        "\n",
        "      id = line['id']\n",
        "      id1 = id + '.s1'\n",
        "      id2 = id + '.s2'\n",
        "\n",
        "      pos = get_wordnet_postag(line['pos'])\n",
        "      lemma = line['lemma']\n",
        "\n",
        "      instance1 = sentence1[int(line['start1']):int(line['end1'])]\n",
        "      instance2 = sentence2[int(line['start2']):int(line['end2'])]\n",
        "\n",
        "      # Add the target token right before and after the word to disambiguate\n",
        "      sentence1 = sentence1.replace(instance1, '[TGT] ' + instance1 + ' [TGT]')\n",
        "      sentence2 = sentence2.replace(instance2, '[TGT] ' + instance2 + ' [TGT]')\n",
        "\n",
        "      # Get all possible senses\n",
        "      senses = wn.lemmas(lemma, pos)\n",
        "\n",
        "      samples1 = []\n",
        "      samples2 = []\n",
        "\n",
        "      # For each sense, we retrieve the gloss and build the BERT inputs\n",
        "      for sense in senses:\n",
        "        synset = sense.synset()\n",
        "        gloss = synset.definition()\n",
        "        examples = ' '.join(synset.examples())\n",
        "        if examples != '':\n",
        "          gloss = gloss + ' [SEP] ' + examples\n",
        "        label1 = int(sense.key() == gold_keys[id1])\n",
        "        label2 = int(sense.key() == gold_keys[id2])\n",
        "      \n",
        "        bert_input1 = tokenizer(sentence1, gloss, return_token_type_ids = True, return_attention_mask = True)\n",
        "        bert_input2 = tokenizer(sentence2, gloss, return_token_type_ids = True, return_attention_mask = True)\n",
        "\n",
        "        samples1.append((bert_input1[\"input_ids\"], bert_input1[\"attention_mask\"], bert_input1[\"token_type_ids\"], label1))\n",
        "        samples2.append((bert_input2[\"input_ids\"], bert_input2[\"attention_mask\"], bert_input2[\"token_type_ids\"], label2))\n",
        "\n",
        "      if (samples1 and samples2):\n",
        "        bert_inputs.append(samples1)\n",
        "        bert_inputs.append(samples2)\n",
        "  \n",
        "  with open(output_file, 'w', encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n",
        "    writer.writerows(bert_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-aWhFk3id8t"
      },
      "source": [
        "# We precompute the BERT inputs and store them in a csv file\n",
        "preprocess_wic_data(path_to_val_data, path_to_val_keys, bert_inputs_wic, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7ZA6GKEjuzw",
        "outputId": "477084ef-b450-4670-fbbb-d23aee66456b"
      },
      "source": [
        "# We show two sub_batches, that as we can see are made up by a different number of samples\n",
        "i = 0\n",
        "with open(bert_inputs_wic) as f:\n",
        "    next(f)\n",
        "    csv_reader = csv.reader(f, delimiter=',')\n",
        "    for row in csv_reader:\n",
        "      for sample in row:\n",
        "        bert_inputs = sample.split('], ')\n",
        "\n",
        "        input_ids = bert_inputs[0][2::].split(',')\n",
        "        attention_mask = bert_inputs[1][1::].split(',')\n",
        "        token_type_ids = bert_inputs[2][1::].split(',')\n",
        "        label = int(bert_inputs[3][:1])\n",
        "\n",
        "        input_ids = torch.tensor(list(map(int, input_ids)))\n",
        "        attention_mask = torch.tensor(list(map(int, attention_mask)))\n",
        "        token_type_ids = torch.tensor(list(map(int, token_type_ids)))\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        print(input_ids)\n",
        "        print(attention_mask)\n",
        "        print(token_type_ids)\n",
        "        print(label)\n",
        "      print('######################################################')\n",
        "      i += 1\n",
        "      if (i == 2):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "         9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "         2375,  1012,   102,  2028,  1997,  3618,  4635,  2030,  2276,  2030,\n",
            "         3737,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(1)\n",
            "tensor([  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "         9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "         2375,  1012,   102,  1996,  2132,  1997,  1037,  3412,  2451,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "         9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "         2375,  1012,   102,  1037,  4337,  4630,  2040,  2003,  2583,  2000,\n",
            "         4154,  9169,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "         9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "         2375,  1012,   102,  1996,  2922, 12573,  2697,  1999,  1996,  2088,\n",
            "         1025,  1996, 17578,  1997,  1996,  2307,  6597,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "         9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "         2375,  1012,   102,  1037,  2237,  1999,  4514,  5273,  2006,  2697,\n",
            "         6020,  2408,  2013, 28218,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "         9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "         2375,  1012,   102,  1037,  2839,  2030,  6454,  2275,  2030,  6267,\n",
            "         2030,  2517,  2682,  1998,  3202,  2000,  2028,  2217,  1997,  2178,\n",
            "         2839,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "######################################################\n",
            "tensor([  101,  2096,  3929,  5204,  2008,  8414,  1998,  2350, 30522, 22983,\n",
            "        30522,  1997,  3412, 12769,  2079,  2025,  2552,  2004,  4505,  2030,\n",
            "        10284,  1997,  1996,  3142, 21179, 13355,  1010,  1996,  2837,  3964,\n",
            "         2008, 15144,  2015,  1999,  3234,  3412,  4449,  2024,  5391,  2011,\n",
            "        22645,  2000,  1996,  4831,  1010,  1999, 10388,  2007, 21975, 27533,\n",
            "         1998, 25186,  1997,  1996,  3642,  1997,  9330,  2375,  1012,   102,\n",
            "         2028,  1997,  3618,  4635,  2030,  2276,  2030,  3737,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2096,  3929,  5204,  2008,  8414,  1998,  2350, 30522, 22983,\n",
            "        30522,  1997,  3412, 12769,  2079,  2025,  2552,  2004,  4505,  2030,\n",
            "        10284,  1997,  1996,  3142, 21179, 13355,  1010,  1996,  2837,  3964,\n",
            "         2008, 15144,  2015,  1999,  3234,  3412,  4449,  2024,  5391,  2011,\n",
            "        22645,  2000,  1996,  4831,  1010,  1999, 10388,  2007, 21975, 27533,\n",
            "         1998, 25186,  1997,  1996,  3642,  1997,  9330,  2375,  1012,   102,\n",
            "         1996,  2132,  1997,  1037,  3412,  2451,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(1)\n",
            "tensor([  101,  2096,  3929,  5204,  2008,  8414,  1998,  2350, 30522, 22983,\n",
            "        30522,  1997,  3412, 12769,  2079,  2025,  2552,  2004,  4505,  2030,\n",
            "        10284,  1997,  1996,  3142, 21179, 13355,  1010,  1996,  2837,  3964,\n",
            "         2008, 15144,  2015,  1999,  3234,  3412,  4449,  2024,  5391,  2011,\n",
            "        22645,  2000,  1996,  4831,  1010,  1999, 10388,  2007, 21975, 27533,\n",
            "         1998, 25186,  1997,  1996,  3642,  1997,  9330,  2375,  1012,   102,\n",
            "         1037,  4337,  4630,  2040,  2003,  2583,  2000,  4154,  9169,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2096,  3929,  5204,  2008,  8414,  1998,  2350, 30522, 22983,\n",
            "        30522,  1997,  3412, 12769,  2079,  2025,  2552,  2004,  4505,  2030,\n",
            "        10284,  1997,  1996,  3142, 21179, 13355,  1010,  1996,  2837,  3964,\n",
            "         2008, 15144,  2015,  1999,  3234,  3412,  4449,  2024,  5391,  2011,\n",
            "        22645,  2000,  1996,  4831,  1010,  1999, 10388,  2007, 21975, 27533,\n",
            "         1998, 25186,  1997,  1996,  3642,  1997,  9330,  2375,  1012,   102,\n",
            "         1996,  2922, 12573,  2697,  1999,  1996,  2088,  1025,  1996, 17578,\n",
            "         1997,  1996,  2307,  6597,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2096,  3929,  5204,  2008,  8414,  1998,  2350, 30522, 22983,\n",
            "        30522,  1997,  3412, 12769,  2079,  2025,  2552,  2004,  4505,  2030,\n",
            "        10284,  1997,  1996,  3142, 21179, 13355,  1010,  1996,  2837,  3964,\n",
            "         2008, 15144,  2015,  1999,  3234,  3412,  4449,  2024,  5391,  2011,\n",
            "        22645,  2000,  1996,  4831,  1010,  1999, 10388,  2007, 21975, 27533,\n",
            "         1998, 25186,  1997,  1996,  3642,  1997,  9330,  2375,  1012,   102,\n",
            "         1037,  2237,  1999,  4514,  5273,  2006,  2697,  6020,  2408,  2013,\n",
            "        28218,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([  101,  2096,  3929,  5204,  2008,  8414,  1998,  2350, 30522, 22983,\n",
            "        30522,  1997,  3412, 12769,  2079,  2025,  2552,  2004,  4505,  2030,\n",
            "        10284,  1997,  1996,  3142, 21179, 13355,  1010,  1996,  2837,  3964,\n",
            "         2008, 15144,  2015,  1999,  3234,  3412,  4449,  2024,  5391,  2011,\n",
            "        22645,  2000,  1996,  4831,  1010,  1999, 10388,  2007, 21975, 27533,\n",
            "         1998, 25186,  1997,  1996,  3642,  1997,  9330,  2375,  1012,   102,\n",
            "         1037,  2839,  2030,  6454,  2275,  2030,  6267,  2030,  2517,  2682,\n",
            "         1998,  3202,  2000,  2028,  2217,  1997,  2178,  2839,   102])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcOZq6KPApj8"
      },
      "source": [
        "### **DataModule definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErEipX-4kTKv"
      },
      "source": [
        "class WiCDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self,\n",
        "               test_data_path: str,\n",
        "               batch_size: int,\n",
        "               collate_fn=None):\n",
        "    \n",
        "    super().__init__()\n",
        "    \n",
        "    # with test set and dataloader only\n",
        "    self.test_data_path = test_data_path\n",
        "    self.collate_fn = collate_fn\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.test_dataset = None\n",
        "  \n",
        "  def setup(self, stage: Optional[str] = None) -> None:\n",
        "    if stage == 'test':\n",
        "      self.test_dataset = WSD_WiC_Dataset(self.test_data_path)\n",
        "\n",
        "  def test_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjZE3T9pkUTU"
      },
      "source": [
        "WiC_dm = WiCDataModule(bert_inputs_wic,\n",
        "                       batch_size=4,\n",
        "                       collate_fn=collate_function)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_K1FJMZ0Wqd",
        "outputId": "05140644-534b-41a3-ad9f-0bb31e70feb2"
      },
      "source": [
        "WiC_dm.setup('test')\n",
        "test_dataloader = WiC_dm.test_dataloader()\n",
        "for batch in test_dataloader:\n",
        "  print(f\"Batch length = : {len(batch)}\")\n",
        "  for sub_batch in batch:\n",
        "    print(f\"Sub-batch length = : {len(sub_batch)}\")\n",
        "    print(sub_batch)\n",
        "    break\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch length = : 4\n",
            "Sub-batch length = : 4\n",
            "(tensor([[  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "          9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "          2375,  1012,   102,  2028,  1997,  3618,  4635,  2030,  2276,  2030,\n",
            "          3737,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "          9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "          2375,  1012,   102,  1996,  2132,  1997,  1037,  3412,  2451,   102,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "          9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "          2375,  1012,   102,  1037,  4337,  4630,  2040,  2003,  2583,  2000,\n",
            "          4154,  9169,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "          9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "          2375,  1012,   102,  1996,  2922, 12573,  2697,  1999,  1996,  2088,\n",
            "          1025,  1996, 17578,  1997,  1996,  2307,  6597,   102,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "          9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "          2375,  1012,   102,  1037,  2237,  1999,  4514,  5273,  2006,  2697,\n",
            "          6020,  2408,  2013, 28218,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,  2053, 11075,  1999,  1037,  3206,  4618,  2022, 10009,  2004,\n",
            "          9345,  4667,  1996,  5368,  1997, 30522, 22983, 30522,  2104,  2248,\n",
            "          2375,  1012,   102,  1037,  2839,  2030,  6454,  2275,  2030,  6267,\n",
            "          2030,  2517,  2682,  1998,  3202,  2000,  2028,  2217,  1997,  2178,\n",
            "          2839,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), tensor([1, 0, 0, 0, 0, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl5M8lnQAvLI"
      },
      "source": [
        "### **Model evaluation on the WiC data for the WSD task**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "141218fe32b34360b32d4f7ac75493a1",
            "43b7187041ed4d7790824a9e6cf7d327",
            "2b4a653926af415a9cb29c6f13f17a6a",
            "fef247af95374ed59b1cc58c166521a3",
            "ad46b865c65947718d373c98d3b0f183",
            "9e98b82996764b1d97c70982e8aee4ee",
            "4785e8683a5d46a79463f6fbf82eb0e6",
            "7b4c5c5de2534d3eb31c1c4d106f9dc7",
            "f023c6b817cd4e82ae4f3976cfe0dd39",
            "cab2582298534bd1b73cccd7516dc36a",
            "4cc264f8b4ce4d8abef02f61f3968bdf"
          ]
        },
        "id": "38RpjIK8kp5e",
        "outputId": "8dcc8d2d-02ea-46b3-a6bd-82ec0e126a6d"
      },
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/Homework3/Results/trained_model_gloss_examples_256-128-d4.pth\"))\n",
        "model.eval()\n",
        "\n",
        "trainer = get_trainer()\n",
        "trainer.test(model=model, datamodule=WiC_dm)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "141218fe32b34360b32d4f7ac75493a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': 0.6782901883125305, 'test_loss': 0.9232341051101685}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_acc': 0.6782901883125305, 'test_loss': 0.9232341051101685}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhyBjdZA2FU"
      },
      "source": [
        "### **Model evaluation on the WiC task**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud3YkF5Y_4xF"
      },
      "source": [
        "# since we do not have the pl.Trainer that sets eval() for us, we have to do it manually\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/Homework3/Results/trained_model_gloss_examples_256-128-d4.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "wic_predictions = []\n",
        "wsd_predictions = []\n",
        "\n",
        "wic_data = []\n",
        "with open(path_to_val_data) as f:\n",
        "    for line in json_lines.reader(f):\n",
        "      wic_data.append(line)\n",
        "\n",
        "for batch_start in range(0, len(wic_data), 4):\n",
        "  wic_prediction, wsd_prediction = model.predict(wic_data[batch_start : batch_start+4])\n",
        "\n",
        "  wic_predictions += wic_prediction\n",
        "  wsd_predictions.extend([elem for prediction in wsd_prediction for elem in prediction])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we312T88J9AM",
        "outputId": "38d7f1cd-83c7-41fb-fd4d-de5dfa08ef07"
      },
      "source": [
        "wsd_labels = get_wsd_labels(path_to_val_keys)\n",
        "wic_labels = get_wic_labels(path_to_val_data)\n",
        "\n",
        "wsd_acc = accuracy_score(wsd_labels, wsd_predictions)\n",
        "print(f'WSD - Accuracy score = {wsd_acc:.4f}')\n",
        "\n",
        "wic_acc = accuracy_score(wic_labels, wic_predictions)\n",
        "print(f'WiC - Accuracy score = {wic_acc:.4f}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WSD - Accuracy score = 0.6709\n",
            "WiC - Accuracy score = 0.7869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akqWdStmFiGe",
        "outputId": "23b34ab9-0414-4b54-b89c-745dd7e264d4"
      },
      "source": [
        "labels = [1 if label == 'True' else 0 for label in wic_labels]\n",
        "predictions = [1 if pred == 'True' else 0 for pred in wic_predictions]\n",
        "\n",
        "print('WiC - CLASSIFICATION REPORT\\n')\n",
        "print(classification_report(labels, predictions, labels=[1, 0], digits=4))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WiC - CLASSIFICATION REPORT\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.8263    0.7800    0.8025       500\n",
            "           0     0.7436    0.7955    0.7687       401\n",
            "\n",
            "    accuracy                         0.7869       901\n",
            "   macro avg     0.7849    0.7878    0.7856       901\n",
            "weighted avg     0.7895    0.7869    0.7874       901\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "ak5xNIi5FgUF",
        "outputId": "33ffa810-8794-4cfb-b6f9-16d649449b8a"
      },
      "source": [
        "data = {'True labels': labels, 'Predicted': predictions}\n",
        "df = pd.DataFrame(data, columns=['True labels','Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['True labels'], df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(confusion_matrix, ax=ax, annot=True, fmt='d')\n",
        "\n",
        "ax.set_title('Confusion Matrix - WiC')\n",
        "ax.set_xlabel('Predictions')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.xaxis.set_ticklabels(['True', 'False'])\n",
        "ax.yaxis.set_ticklabels(['True', 'False'])\n",
        "\n",
        "print()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}